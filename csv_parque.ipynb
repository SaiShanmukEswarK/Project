{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a23cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.9 (from pyspark)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "\u001b[33m  DEPRECATION: Building 'pyspark' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyspark'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813861 sha256=187c365071a44738acb2e28b8c6e4d11d7e979e3ba8f577774747e51f9b74560\n",
      "  Stored in directory: /Users/compiling/Library/Caches/pip/wheels/00/e3/92/8594f4cee2c9fd4ad82fe85e4bf2559ab8ea84ef19b1dd3d15\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyspark]m1/2\u001b[0m [pyspark]\n",
      "\u001b[1A\u001b[2KSuccessfully installed py4j-0.10.9.9 pyspark-4.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c46841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/01 10:53:30 WARN Utils: Your hostname, compilings-Mac-mini.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.237 instead (on interface en0)\n",
      "25/12/01 10:53:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/01 10:53:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /s/chopin/b/grad/C837217249/project/fd/pums_2019.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/01 10:53:33 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: /s/chopin/b/grad/C837217249/project/fd/pums_2019.csv.\n",
      "java.io.FileNotFoundException: File /s/chopin/b/grad/C837217249/project/fd/pums_2019.csv does not exist\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n",
      "\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n",
      "\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:392)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.csv(DataFrameReader.scala:259)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/s/chopin/b/grad/C837217249/project/fd/pums_2019.csv. SQLSTATE: 42K03",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m parquet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pums_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     18\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m       \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m---> 21\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparquet_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m (\n\u001b[1;32m     26\u001b[0m     df\u001b[38;5;241m.\u001b[39mwrite\n\u001b[1;32m     27\u001b[0m       \u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[1;32m     28\u001b[0m       \u001b[38;5;241m.\u001b[39mparquet(parquet_path)\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pyspark/sql/readwriter.py:838\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_only():\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RDD  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/py4j/java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    284\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/s/chopin/b/grad/C837217249/project/fd/pums_2019.csv. SQLSTATE: 42K03"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CSV_to_Parquet_PUMS\").getOrCreate()\n",
    "\n",
    "\n",
    "input_dir = \"/s/chopin/b/grad/C837217249/project/fd\"\n",
    "output_dir = \"/s/chopin/b/grad/C837217249/project/parque_data\"\n",
    "\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "for year in years:\n",
    "    csv_path = f\"{input_dir}/pums_{year}.csv\"\n",
    "    parquet_path = f\"{output_dir}/pums_{year}.parquet\"\n",
    "    \n",
    "    print(f\"Reading {csv_path} ...\")\n",
    "    df = (\n",
    "        spark.read\n",
    "             .option(\"header\", \"true\")       \n",
    "             .option(\"inferSchema\", \"true\")  \n",
    "             .csv(csv_path)\n",
    "    )\n",
    "\n",
    "    print(f\"Writing {parquet_path} ...\")\n",
    "    (\n",
    "        df.write\n",
    "          .mode(\"overwrite\")   \n",
    "          .parquet(parquet_path)\n",
    "    )\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb637c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:20:23 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet.\n",
      "java.io.FileNotFoundException: File /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet does not exist\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n",
      "\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:457)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:306)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:58)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4810.parquet.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\npy4j.ClientServerConnection.run(ClientServerConnection.java:108)\njava.base/java.lang.Thread.run(Thread.java:840)\n\nAnd it was stopped at:\n\norg.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:552)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\npy4j.ClientServerConnection.run(ClientServerConnection.java:108)\njava.base/java.lang.Thread.run(Thread.java:840)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)\n\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2872)\n\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:498)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:133)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:80)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:219)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:216)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:422)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n\tat scala.util.Try$.apply(Try.scala:217)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:457)\n\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:306)\n\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:58)\n\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)\n\t\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2872)\n\t\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:63)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:498)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:133)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:80)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:219)\n\t\tat scala.Option.orElse(Option.scala:477)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:216)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:422)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n\t\tat scala.Option.getOrElse(Option.scala:201)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n\t\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n\t\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n\t\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n\t\tat scala.collection.immutable.List.foreach(List.scala:334)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n\t\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n\t\tat scala.util.Try$.apply(Try.scala:217)\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n\t\t... 22 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_all \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py:642\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    631\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    633\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    634\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    640\u001b[0m )\n\u001b[0;32m--> 642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:282\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    284\u001b[0m     converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:327\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4810.parquet.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\npy4j.ClientServerConnection.run(ClientServerConnection.java:108)\njava.base/java.lang.Thread.run(Thread.java:840)\n\nAnd it was stopped at:\n\norg.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:552)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\npy4j.ClientServerConnection.run(ClientServerConnection.java:108)\njava.base/java.lang.Thread.run(Thread.java:840)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)\n\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2872)\n\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:498)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:133)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:80)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:219)\n\tat scala.Option.orElse(Option.scala:477)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:216)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:422)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n\tat scala.util.Try$.apply(Try.scala:217)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:457)\n\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:306)\n\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:58)\n\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:128)\n\t\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2872)\n\t\tat org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.mergeSchemasInParallel(SchemaMergeUtils.scala:63)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:498)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$.inferSchema(ParquetUtils.scala:133)\n\t\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:80)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:219)\n\t\tat scala.Option.orElse(Option.scala:477)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:216)\n\t\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:422)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n\t\tat scala.Option.getOrElse(Option.scala:201)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n\t\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n\t\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n\t\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n\t\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n\t\tat scala.collection.immutable.List.foreach(List.scala:334)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n\t\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\t\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n\t\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n\t\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n\t\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\t\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n\t\tat scala.util.Try$.apply(Try.scala:217)\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n\t\t... 22 more\n"
     ]
    }
   ],
   "source": [
    "df_all = spark.read.parquet(\"/s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9732d4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/30 07:56:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/30 07:56:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Explore_PUMS\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fe5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6173c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:20:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/30 09:20:26 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet.\n",
      "java.io.FileNotFoundException: File /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet does not exist\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n",
      "\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:457)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:306)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:58)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Explore_PUMS\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "df = spark.read.parquet(\n",
    "    \"/s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35c94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9b40aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/s/chopin/b/grad/C837217249/project/parque_data\n",
      "/s/chopin/b/grad/C837217249/project/parque_data/pums_2021.parquet\n",
      "    .part-00011-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00017-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00015-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00011-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00000-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00016-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00004-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00013-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00012-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    _SUCCESS\n",
      "    part-00019-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00016-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00021-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00015-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00005-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00002-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00001-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00001-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00018-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00019-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00000-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    ._SUCCESS.crc\n",
      "    .part-00018-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00006-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00003-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00009-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00008-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00017-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00006-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00007-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00008-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00004-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00009-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00020-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00010-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00005-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00010-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00020-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00014-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    .part-00021-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00007-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00012-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00013-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    .part-00003-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet.crc\n",
      "    part-00002-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "    part-00014-a53d95f1-ea31-461f-87a3-4be8018dad86-c000.snappy.parquet\n",
      "/s/chopin/b/grad/C837217249/project/parque_data/pums_2022.parquet\n",
      "    .part-00016-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00010-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00002-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00017-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00000-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00012-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00014-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00020-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00008-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00005-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00008-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    _SUCCESS\n",
      "    .part-00001-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00004-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00011-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00020-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00007-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    ._SUCCESS.crc\n",
      "    part-00019-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00015-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00018-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00009-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00010-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00006-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00011-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00006-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00003-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00007-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00005-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00003-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00002-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00013-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00004-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00009-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00018-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00012-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00014-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00013-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00000-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    part-00001-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "    .part-00015-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00017-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    .part-00019-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet.crc\n",
      "    part-00016-5ec79578-2496-49fc-853a-704e07944c64-c000.snappy.parquet\n",
      "/s/chopin/b/grad/C837217249/project/parque_data/pums_2020.parquet\n",
      "    .part-00016-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00000-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00003-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00007-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00007-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00002-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00005-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00014-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00010-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00006-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00017-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00011-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00010-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    _SUCCESS\n",
      "    part-00002-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00020-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00012-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00018-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    ._SUCCESS.crc\n",
      "    part-00004-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00020-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00003-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00019-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00005-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00009-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00015-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00000-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00009-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00008-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00006-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00001-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00015-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00004-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00018-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00014-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00008-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00001-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00016-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    part-00019-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00013-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00011-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    part-00013-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet\n",
      "    .part-00017-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "    .part-00012-6353b105-992c-42d1-8ef8-5866c4897094-c000.snappy.parquet.crc\n",
      "/s/chopin/b/grad/C837217249/project/parque_data/pums_2023.parquet\n",
      "    .part-00004-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00005-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00000-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00013-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00017-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00008-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00014-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00020-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00004-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00019-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    _SUCCESS\n",
      "    part-00015-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00018-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00010-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00011-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00011-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00006-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    ._SUCCESS.crc\n",
      "    .part-00003-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00013-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00012-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00016-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00019-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00007-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00001-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00015-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00003-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00001-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00002-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00000-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00016-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00009-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00002-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00018-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00010-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    part-00009-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00005-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00006-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00014-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00007-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    .part-00008-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00017-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "    .part-00012-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet.crc\n",
      "    part-00020-58b6cc49-1009-4c04-b701-7c7983c34bf7-c000.snappy.parquet\n",
      "/s/chopin/b/grad/C837217249/project/parque_data/pums_2019.parquet\n",
      "    part-00020-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00006-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00017-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00004-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00000-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00007-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00019-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00007-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00008-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    _SUCCESS\n",
      "    part-00010-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00001-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00002-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00006-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    ._SUCCESS.crc\n",
      "    part-00011-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00016-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00009-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00008-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00013-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00018-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00014-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00005-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00003-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00003-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00012-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00009-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00002-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00000-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00001-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00016-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00020-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00019-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00015-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    part-00013-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00005-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00017-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n",
      "    .part-00014-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00015-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00011-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00010-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00004-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    .part-00012-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet.crc\n",
      "    part-00018-b711a5ca-a8ec-4aa2-8c37-efe373fbd38a-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base = \"/s/chopin/b/grad/C837217249/project/parque_data\"\n",
    "for root, dirs, files in os.walk(base):\n",
    "    print(root)\n",
    "    for f in files:\n",
    "        print(\"   \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfa11674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rows = df.limit(50).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9fa2205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>24</td>\n",
       "      <td>2023GQ0000068</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>32</td>\n",
       "      <td>2023GQ0000094</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000104</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>9290.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>42</td>\n",
       "      <td>2023GQ0000117</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>2023GQ0000119</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000151</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>770.0</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000195</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>2023GQ0000215</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>47</td>\n",
       "      <td>2023GQ0000237</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>8780.0</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>42</td>\n",
       "      <td>2023GQ0000248</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000252</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>770.0</td>\n",
       "      <td>5860.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000268</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>8680.0</td>\n",
       "      <td>4140.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023</td>\n",
       "      <td>36</td>\n",
       "      <td>2023GQ0000292</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000297</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023</td>\n",
       "      <td>41</td>\n",
       "      <td>2023GQ0000300</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023</td>\n",
       "      <td>13</td>\n",
       "      <td>2023GQ0000313</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023</td>\n",
       "      <td>36</td>\n",
       "      <td>2023GQ0000339</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>2023GQ0000367</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "      <td>2023GQ0000402</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>2023GQ0000406</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2023GQ0000419</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>34</td>\n",
       "      <td>2023GQ0000427</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000453</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "      <td>2023GQ0000468</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000475</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2023GQ0000485</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>2023GQ0000490</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000498</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>2023GQ0000522</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>7870.0</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>36</td>\n",
       "      <td>2023GQ0000539</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>49</td>\n",
       "      <td>2023GQ0000552</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>6970.0</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>2023GQ0000566</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>2023GQ0000619</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023</td>\n",
       "      <td>26</td>\n",
       "      <td>2023GQ0000623</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023GQ0000625</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023</td>\n",
       "      <td>51</td>\n",
       "      <td>2023GQ0000632</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023</td>\n",
       "      <td>42</td>\n",
       "      <td>2023GQ0000642</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>9005.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023</td>\n",
       "      <td>53</td>\n",
       "      <td>2023GQ0000666</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000689</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023</td>\n",
       "      <td>49</td>\n",
       "      <td>2023GQ0000701</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>2023GQ0000732</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023</td>\n",
       "      <td>36</td>\n",
       "      <td>2023GQ0000851</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7390.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "      <td>2023GQ0000858</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>9170.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0000869</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>770.0</td>\n",
       "      <td>7420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023</td>\n",
       "      <td>20</td>\n",
       "      <td>2023GQ0000871</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023</td>\n",
       "      <td>51</td>\n",
       "      <td>2023GQ0000886</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>8590.0</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2023GQ0000932</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023</td>\n",
       "      <td>39</td>\n",
       "      <td>2023GQ0000945</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023</td>\n",
       "      <td>24</td>\n",
       "      <td>2023GQ0000970</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "      <td>2023GQ0001015</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1              2   3    4   5   6   7   8   9   ...  22      23  \\\n",
       "0   2023  24  2023GQ0000068   1   27  62   1   5   1   2  ...  17     NaN   \n",
       "1   2023  32  2023GQ0000094   1   53  30   1   1   2   2  ...  14     NaN   \n",
       "2   2023  48  2023GQ0000104   1   21  33   2   4   1   2  ...  14  9290.0   \n",
       "3   2023  42  2023GQ0000117   1   14  90   1   2   1   2  ...  12     NaN   \n",
       "4   2023  29  2023GQ0000119   1   19  83   2   3   1   2  ...  20     NaN   \n",
       "5   2023  48  2023GQ0000151   1   64  57   1   1   1   2  ...  17   770.0   \n",
       "6   2023  48  2023GQ0000195   1   60  18   1   5   1   2  ...  16  9680.0   \n",
       "7   2023   4  2023GQ0000215   1   82  36   1   5   1   2  ...  22     NaN   \n",
       "8   2023  47  2023GQ0000237   1   14  22   1   5   1   2  ...  18  8780.0   \n",
       "9   2023  42  2023GQ0000248   1   55  20   2   5   1   2  ...  19     NaN   \n",
       "10  2023   6  2023GQ0000252   1   86  19   2   5   1   2  ...  19   770.0   \n",
       "11  2023  48  2023GQ0000268   1   49  49   1   4   2   2  ...  12  8680.0   \n",
       "12  2023  36  2023GQ0000292   1   26  74   2   2   1   2  ...  14     NaN   \n",
       "13  2023   6  2023GQ0000297   1   60  69   1   1   1   2  ...  19     NaN   \n",
       "14  2023  41  2023GQ0000300   1    6  85   1   5   1   2  ...  22     NaN   \n",
       "15  2023  13  2023GQ0000313   1    8  57   2   1   1   2  ...  13     NaN   \n",
       "16  2023  36  2023GQ0000339   1   77  18   2   5   1   1  ...  19     NaN   \n",
       "17  2023  17  2023GQ0000367   1   21  80   2   2   1   2  ...  20     NaN   \n",
       "18  2023  21  2023GQ0000402   1   41  19   1   5   1   1  ...  19  3570.0   \n",
       "19  2023  22  2023GQ0000406   1   50  32   1   5   1   2  ...  16  1180.0   \n",
       "20  2023   5  2023GQ0000419   1   41  18   2   5   1   1  ...  16     NaN   \n",
       "21  2023  34  2023GQ0000427   1   61  19   2   5   1   1  ...  19  8470.0   \n",
       "22  2023   6  2023GQ0000453   1  163  35   2   5   2   2  ...  16  9160.0   \n",
       "23  2023  15  2023GQ0000468   1   43  64   2   5   1   2  ...  12     NaN   \n",
       "24  2023   6  2023GQ0000475   1   11  28   1   5   1   2  ...  17  9920.0   \n",
       "25  2023   5  2023GQ0000485   1   13  75   1   3   1   2  ...  16     NaN   \n",
       "26  2023  29  2023GQ0000490   1  100  69   2   3   1   2  ...  19     NaN   \n",
       "27  2023   6  2023GQ0000498   1   14  74   2   1   1   2  ...  16     NaN   \n",
       "28  2023  17  2023GQ0000522   1   60  21   2   5   1   1  ...  19  7870.0   \n",
       "29  2023  36  2023GQ0000539   1   10  56   1   5   1   2  ...  16     NaN   \n",
       "30  2023  49  2023GQ0000552   1   60  20   1   5   1   2  ...  18  6970.0   \n",
       "31  2023  29  2023GQ0000566   1   34  76   1   5   1   2  ...  16     NaN   \n",
       "32  2023  22  2023GQ0000619   1   76  52   1   1   2   2  ...  16     NaN   \n",
       "33  2023  26  2023GQ0000623   1   46  20   1   5   1   2  ...  19  6380.0   \n",
       "34  2023   6  2023GQ0000625   1    6  15   2   5   1   2  ...  12     NaN   \n",
       "35  2023  51  2023GQ0000632   1   48  18   2   5   1   1  ...  16  8670.0   \n",
       "36  2023  42  2023GQ0000642   1   66  30   1   5   1   2  ...  16  6380.0   \n",
       "37  2023  53  2023GQ0000666   1   11  79   2   3   1   2  ...  21     NaN   \n",
       "38  2023  48  2023GQ0000689   1   60  76   2   2   1   2  ...  21     NaN   \n",
       "39  2023  49  2023GQ0000701   1    6  40   2   5   1   2  ...  16     NaN   \n",
       "40  2023  12  2023GQ0000732   1  104  18   2   5   1   2  ...  16  8470.0   \n",
       "41  2023  36  2023GQ0000851   1   62  18   2   5   1   2  ...  18  7390.0   \n",
       "42  2023  29  2023GQ0000858   1    8  79   2   5   1   2  ...  22  9170.0   \n",
       "43  2023  48  2023GQ0000869   1   58  24   1   5   2   2  ...  16   770.0   \n",
       "44  2023  20  2023GQ0000871   1   32  32   2   5   1   2  ...  16     NaN   \n",
       "45  2023  51  2023GQ0000886   1  115  19   2   5   1   1  ...  16  8590.0   \n",
       "46  2023   8  2023GQ0000932   1    2  51   1   1   2   2  ...  16     NaN   \n",
       "47  2023  39  2023GQ0000945   1   51  35   1   5   2   2  ...  18     NaN   \n",
       "48  2023  24  2023GQ0000970   1    9  90   2   3   1   2  ...  16     NaN   \n",
       "49  2023  48  2023GQ0001015   1   15  81   2   4   1   2  ...  14     NaN   \n",
       "\n",
       "        24  25  26  27   28    29    30   31  \n",
       "0      NaN   1   1   1  NaN  None  None  4.0  \n",
       "1      NaN   2   2   2  NaN  None  None  4.0  \n",
       "2   4230.0   2   2   1  2.0  None  None  4.0  \n",
       "3      NaN   1   1   1  NaN  None  None  4.0  \n",
       "4      NaN   1   2   1  NaN  None  None  4.0  \n",
       "5   6230.0   2   2   2  NaN  None  None  4.0  \n",
       "6   3870.0   2   2   2  NaN  None  None  1.0  \n",
       "7      NaN   2   2   2  NaN  None  None  4.0  \n",
       "8   4700.0   2   2   2  NaN  None  None  4.0  \n",
       "9      NaN   2   2   2  2.0  None  None  4.0  \n",
       "10  5860.0   2   2   2  2.0  None  None  4.0  \n",
       "11  4140.0   2   1   1  NaN  None  None  4.0  \n",
       "12     NaN   1   1   1  NaN  None  None  4.0  \n",
       "13     NaN   1   1   1  NaN  None  None  4.0  \n",
       "14     NaN   1   1   1  NaN  None  None  4.0  \n",
       "15     NaN   1   1   1  NaN  None  None  4.0  \n",
       "16     NaN   2   2   2  2.0  None  None  4.0  \n",
       "17     NaN   1   1   1  NaN  None  None  4.0  \n",
       "18  7750.0   2   2   2  NaN  None  None  4.0  \n",
       "19   440.0   2   2   2  NaN  None  None  4.0  \n",
       "20     NaN   2   2   2  2.0  None  None  4.0  \n",
       "21  4622.0   2   2   2  2.0  None  None  4.0  \n",
       "22  2060.0   2   2   2  2.0  None  None  4.0  \n",
       "23     NaN   1   1   1  NaN  None  None  4.0  \n",
       "24  9920.0   2   2   2  NaN  None  None  4.0  \n",
       "25     NaN   1   1   1  NaN  None  None  2.0  \n",
       "26     NaN   1   1   1  NaN  None  None  4.0  \n",
       "27     NaN   1   1   1  NaN  None  None  4.0  \n",
       "28  4640.0   2   2   2  2.0  None  None  4.0  \n",
       "29     NaN   2   2   1  NaN  None  None  4.0  \n",
       "30  5240.0   2   2   2  NaN  None  None  4.0  \n",
       "31     NaN   1   1   1  NaN  None  None  4.0  \n",
       "32     NaN   2   2   2  NaN  None  None  2.0  \n",
       "33  5510.0   2   2   2  NaN  None  None  4.0  \n",
       "34     NaN   2   2   1  1.0  None  None  NaN  \n",
       "35  4622.0   2   2   2  2.0  None  None  4.0  \n",
       "36  9005.0   2   2   2  NaN  None  None  4.0  \n",
       "37     NaN   1   1   1  NaN  None  None  4.0  \n",
       "38     NaN   1   1   1  NaN  None  None  4.0  \n",
       "39     NaN   1   2   1  2.0  None  None  4.0  \n",
       "40  4621.0   2   2   2  2.0  None  None  4.0  \n",
       "41  5400.0   2   2   2  2.0  None  None  4.0  \n",
       "42   726.0   2   1   1  NaN  None  None  4.0  \n",
       "43  7420.0   2   2   2  NaN  None  None  4.0  \n",
       "44     NaN   2   2   2  2.0  None  None  4.0  \n",
       "45  3960.0   2   2   1  2.0  None  None  4.0  \n",
       "46     NaN   2   2   2  NaN  None  None  4.0  \n",
       "47     NaN   2   2   2  NaN  None  None  4.0  \n",
       "48     NaN   1   1   1  NaN  None  None  4.0  \n",
       "49     NaN   2   1   1  NaN  None  None  4.0  \n",
       "\n",
       "[50 rows x 32 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = pd.DataFrame(rows)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bee6fdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      "\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+----+----+-----+----+----+----+----+----+----+---+----+--------+----+---+\n",
      "|YEAR| ST|     SERIALNO|SPORDER|PWGTP|AGEP|SEX|MAR|HICOV|HINS1|HINS2|HINS3|HINS4|HINS5|HINS6|POVPIP|PINCP|ESR|WAGP|SEMP|  SSP|RETP|SCHL|INDP|OCCP|DOUT|DPHY|DIS| FER|BROADBND| VEH|MIL|\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+----+----+-----+----+----+----+----+----+----+---+----+--------+----+---+\n",
      "|2023| 24|2023GQ0000068|      1|   27|  62|  1|  5|    1|    2|    2|    1|    1|    2|    2|   122|19300|  6|   0|   0|19300|   0|  17|NULL|NULL|   1|   1|  1|NULL|    NULL|NULL|  4|\n",
      "|2023| 32|2023GQ0000094|      1|   53|  30|  1|  1|    2|    2|    2|    2|    2|    2|    2|  NULL|    0|  6|   0|   0|    0|   0|  14|NULL|NULL|   2|   2|  2|NULL|    NULL|NULL|  4|\n",
      "|2023| 48|2023GQ0000104|      1|   21|  33|  2|  4|    1|    2|    2|    2|    1|    2|    2|    38| 6000|  1|   0|3600|    0|   0|  14|9290|4230|   2|   2|  1|   2|    NULL|NULL|  4|\n",
      "|2023| 42|2023GQ0000117|      1|   14|  90|  1|  2|    1|    2|    2|    1|    1|    2|    2|  NULL|27600|  6|   0|   0|25600|2000|  12|NULL|NULL|   1|   1|  1|NULL|    NULL|NULL|  4|\n",
      "|2023| 29|2023GQ0000119|      1|   19|  83|  2|  3|    1|    2|    1|    1|    1|    2|    2|  NULL|    0|  6|   0|   0|    0|   0|  20|NULL|NULL|   1|   2|  1|NULL|    NULL|NULL|  4|\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+----+----+-----+----+----+----+----+----+----+---+----+--------+----+---+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:20:43 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet.\n",
      "java.io.FileNotFoundException: File /s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet does not exist\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n",
      "\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:457)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:306)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.parquet(DataFrameReader.scala:58)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\n",
    "    \"/s/chopin/b/grad/C837217249/project/parque_data/pums_*.parquet\"\n",
    ")\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adb1db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 15912393\n",
      "Total columns: 32\n"
     ]
    }
   ],
   "source": [
    "# total rows\n",
    "total_rows = df.count()\n",
    "print(\"Total rows:\", total_rows)\n",
    "\n",
    "# total columns\n",
    "print(\"Total columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e906c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=====================================>                  (14 + 7) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+------------------+\n",
      "|  column|null_count|non_null_count|      null_percent|\n",
      "+--------+----------+--------------+------------------+\n",
      "|     FER|  12544895|       3367498| 78.83726225213266|\n",
      "|    INDP|   6463135|       9449258| 40.61698953765156|\n",
      "|    OCCP|   6463135|       9449258| 40.61698953765156|\n",
      "|     MIL|   2866342|      13046051|18.013268023231955|\n",
      "|     ESR|   2675152|      13237241|16.811751695675188|\n",
      "|   PINCP|   2484356|      13428037|  15.6127114256165|\n",
      "|    WAGP|   2484356|      13428037|  15.6127114256165|\n",
      "|    SEMP|   2484356|      13428037|  15.6127114256165|\n",
      "|     SSP|   2484356|      13428037|  15.6127114256165|\n",
      "|    RETP|   2484356|      13428037|  15.6127114256165|\n",
      "|    DOUT|   2484356|      13428037|  15.6127114256165|\n",
      "|BROADBND|   1934152|      13978241|12.155003964519981|\n",
      "|     VEH|    854342|      15058051|5.3690353173152525|\n",
      "|    DPHY|    743189|      15169204|  4.67050430441229|\n",
      "|  POVPIP|    731631|      15180762| 4.597869094862099|\n",
      "|    SCHL|    432580|      15479813|2.7185100317720914|\n",
      "|    YEAR|         0|      15912393|               0.0|\n",
      "|      ST|         0|      15912393|               0.0|\n",
      "|SERIALNO|         0|      15912393|               0.0|\n",
      "| SPORDER|         0|      15912393|               0.0|\n",
      "|   PWGTP|         0|      15912393|               0.0|\n",
      "|    AGEP|         0|      15912393|               0.0|\n",
      "|     SEX|         0|      15912393|               0.0|\n",
      "|     MAR|         0|      15912393|               0.0|\n",
      "|   HICOV|         0|      15912393|               0.0|\n",
      "|   HINS1|         0|      15912393|               0.0|\n",
      "|   HINS2|         0|      15912393|               0.0|\n",
      "|   HINS3|         0|      15912393|               0.0|\n",
      "|   HINS4|         0|      15912393|               0.0|\n",
      "|   HINS5|         0|      15912393|               0.0|\n",
      "|   HINS6|         0|      15912393|               0.0|\n",
      "|     DIS|         0|      15912393|               0.0|\n",
      "+--------+----------+--------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, sum as _sum, count, expr\n",
    "\n",
    "total_rows = df.count()\n",
    "\n",
    "# null for single row\n",
    "null_counts_row = df.select([\n",
    "    _sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "\n",
    "stack_expr = \"stack({n}, {pairs}) as (column, null_count)\".format(\n",
    "    n=len(df.columns),\n",
    "    pairs=\", \".join([f\"'{c}', `{c}`\" for c in df.columns])\n",
    ")\n",
    "\n",
    "nulls_long = null_counts_row.selectExpr(stack_expr)\n",
    "\n",
    "\n",
    "null_report = (\n",
    "    nulls_long\n",
    "    .withColumn(\"non_null_count\", expr(f\"{total_rows} - null_count\"))\n",
    "    .withColumn(\"null_percent\", (col(\"null_count\") / total_rows) * 100)\n",
    "    .orderBy(col(\"null_percent\").desc())\n",
    ")\n",
    "\n",
    "null_report.show(35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fd446de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "YEAR: 2019\n",
      "================================================================================\n",
      "Total rows in 2019: 3239553\n",
      "\n",
      "Null report per column for 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+------------------+\n",
      "|column  |null_count|non_null_count|null_percent      |\n",
      "+--------+----------+--------------+------------------+\n",
      "|FER     |2551151   |688402        |78.7500929912244  |\n",
      "|INDP    |1316208   |1923345       |40.629309043562486|\n",
      "|OCCP    |1316208   |1923345       |40.629309043562486|\n",
      "|MIL     |601405    |2638148       |18.564443921738587|\n",
      "|ESR     |562743    |2676810       |17.371007666798473|\n",
      "|PINCP   |523944    |2715609       |16.173342433354232|\n",
      "|WAGP    |523944    |2715609       |16.173342433354232|\n",
      "|SEMP    |523944    |2715609       |16.173342433354232|\n",
      "|SSP     |523944    |2715609       |16.173342433354232|\n",
      "|RETP    |523944    |2715609       |16.173342433354232|\n",
      "|DOUT    |523944    |2715609       |16.173342433354232|\n",
      "|BROADBND|432406    |2807147       |13.347705686556138|\n",
      "|DPHY    |159048    |3080505       |4.909566227192455 |\n",
      "|VEH     |151321    |3088232       |4.6710456658681   |\n",
      "|POVPIP  |132970    |3106583       |4.104578625507902 |\n",
      "|SCHL    |92298     |3147255       |2.849096773536349 |\n",
      "|YEAR    |0         |3239553       |0.0               |\n",
      "|ST      |0         |3239553       |0.0               |\n",
      "|SERIALNO|0         |3239553       |0.0               |\n",
      "|SPORDER |0         |3239553       |0.0               |\n",
      "|PWGTP   |0         |3239553       |0.0               |\n",
      "|AGEP    |0         |3239553       |0.0               |\n",
      "|SEX     |0         |3239553       |0.0               |\n",
      "|MAR     |0         |3239553       |0.0               |\n",
      "|HICOV   |0         |3239553       |0.0               |\n",
      "|HINS1   |0         |3239553       |0.0               |\n",
      "|HINS2   |0         |3239553       |0.0               |\n",
      "|HINS3   |0         |3239553       |0.0               |\n",
      "|HINS4   |0         |3239553       |0.0               |\n",
      "|HINS5   |0         |3239553       |0.0               |\n",
      "|HINS6   |0         |3239553       |0.0               |\n",
      "|DIS     |0         |3239553       |0.0               |\n",
      "+--------+----------+--------------+------------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "YEAR: 2020\n",
      "================================================================================\n",
      "Total rows in 2020: 2641054\n",
      "\n",
      "Null report per column for 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------+------------------+\n",
      "|column    |null_count|non_null_count|null_percent      |\n",
      "+----------+----------+--------------+------------------+\n",
      "|FER       |2081090   |559964        |78.79770727898786 |\n",
      "|INDP      |1082284   |1558770       |40.97924540732601 |\n",
      "|OCCP      |1082284   |1558770       |40.97924540732601 |\n",
      "|MIL       |471793    |2169261       |17.863814976899377|\n",
      "|ESR       |440438    |2200616       |16.67659956971724 |\n",
      "|PINCP     |409281    |2231773       |15.496881169411909|\n",
      "|WAGP      |409281    |2231773       |15.496881169411909|\n",
      "|SEMP      |409281    |2231773       |15.496881169411909|\n",
      "|SSP       |409281    |2231773       |15.496881169411909|\n",
      "|RETP      |409281    |2231773       |15.496881169411909|\n",
      "|DOUT      |409281    |2231773       |15.496881169411909|\n",
      "|BROADBND  |378472    |2262582       |14.330339326647618|\n",
      "|ACCESSINET|186031    |2455023       |7.043816597464497 |\n",
      "|VEH       |186031    |2455023       |7.043816597464497 |\n",
      "|POVPIP    |155986    |2485068       |5.906202599416748 |\n",
      "|DPHY      |122806    |2518248       |4.6498859924863325|\n",
      "|SCHL      |71175     |2569879       |2.69494679018301  |\n",
      "|YEAR      |0         |2641054       |0.0               |\n",
      "|ST        |0         |2641054       |0.0               |\n",
      "|SERIALNO  |0         |2641054       |0.0               |\n",
      "|SPORDER   |0         |2641054       |0.0               |\n",
      "|PWGTP     |0         |2641054       |0.0               |\n",
      "|AGEP      |0         |2641054       |0.0               |\n",
      "|SEX       |0         |2641054       |0.0               |\n",
      "|MAR       |0         |2641054       |0.0               |\n",
      "|HICOV     |0         |2641054       |0.0               |\n",
      "|HINS1     |0         |2641054       |0.0               |\n",
      "|HINS2     |0         |2641054       |0.0               |\n",
      "|HINS3     |0         |2641054       |0.0               |\n",
      "|HINS4     |0         |2641054       |0.0               |\n",
      "|HINS5     |0         |2641054       |0.0               |\n",
      "|HINS6     |0         |2641054       |0.0               |\n",
      "|DIS       |0         |2641054       |0.0               |\n",
      "+----------+----------+--------------+------------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "YEAR: 2021\n",
      "================================================================================\n",
      "Total rows in 2021: 3252599\n",
      "\n",
      "Null report per column for 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------+------------------+\n",
      "|column    |null_count|non_null_count|null_percent      |\n",
      "+----------+----------+--------------+------------------+\n",
      "|FER       |2564555   |688044        |78.84633181034613 |\n",
      "|INDP      |1326438   |1926161       |40.780864779211946|\n",
      "|OCCP      |1326438   |1926161       |40.780864779211946|\n",
      "|MIL       |589171    |2663428       |18.113852952669543|\n",
      "|ESR       |549819    |2702780       |16.903989701773874|\n",
      "|PINCP     |510878    |2741721       |15.706762499773259|\n",
      "|WAGP      |510878    |2741721       |15.706762499773259|\n",
      "|SEMP      |510878    |2741721       |15.706762499773259|\n",
      "|SSP       |510878    |2741721       |15.706762499773259|\n",
      "|RETP      |510878    |2741721       |15.706762499773259|\n",
      "|DOUT      |510878    |2741721       |15.706762499773259|\n",
      "|BROADBND  |377176    |2875423       |11.596142039027866|\n",
      "|HHLDRAGEP |159855    |3092744       |4.914685148707234 |\n",
      "|ACCESSINET|159855    |3092744       |4.914685148707234 |\n",
      "|VEH       |159855    |3092744       |4.914685148707234 |\n",
      "|DPHY      |151838    |3100761       |4.66820533364242  |\n",
      "|POVPIP    |139436    |3113163       |4.286910252385861 |\n",
      "|SCHL      |88108     |3164491       |2.70884913879639  |\n",
      "|YEAR      |0         |3252599       |0.0               |\n",
      "|ST        |0         |3252599       |0.0               |\n",
      "|SERIALNO  |0         |3252599       |0.0               |\n",
      "|SPORDER   |0         |3252599       |0.0               |\n",
      "|PWGTP     |0         |3252599       |0.0               |\n",
      "|AGEP      |0         |3252599       |0.0               |\n",
      "|SEX       |0         |3252599       |0.0               |\n",
      "|MAR       |0         |3252599       |0.0               |\n",
      "|HICOV     |0         |3252599       |0.0               |\n",
      "|HINS1     |0         |3252599       |0.0               |\n",
      "|HINS2     |0         |3252599       |0.0               |\n",
      "|HINS3     |0         |3252599       |0.0               |\n",
      "|HINS4     |0         |3252599       |0.0               |\n",
      "|HINS5     |0         |3252599       |0.0               |\n",
      "|HINS6     |0         |3252599       |0.0               |\n",
      "|DIS       |0         |3252599       |0.0               |\n",
      "+----------+----------+--------------+------------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "YEAR: 2022\n",
      "================================================================================\n",
      "Total rows in 2022: 3373378\n",
      "\n",
      "Null report per column for 2022\n",
      "+----------+----------+--------------+------------------+\n",
      "|column    |null_count|non_null_count|null_percent      |\n",
      "+----------+----------+--------------+------------------+\n",
      "|FER       |2659564   |713814        |78.83978611350403 |\n",
      "|INDP      |1366240   |2007138       |40.50064949732879 |\n",
      "|OCCP      |1366240   |2007138       |40.50064949732879 |\n",
      "|MIL       |604751    |2768627       |17.927163810281563|\n",
      "|ESR       |563988    |2809390       |16.718790482418513|\n",
      "|PINCP     |522876    |2850502       |15.500071441741781|\n",
      "|WAGP      |522876    |2850502       |15.500071441741781|\n",
      "|SEMP      |522876    |2850502       |15.500071441741781|\n",
      "|SSP       |522876    |2850502       |15.500071441741781|\n",
      "|RETP      |522876    |2850502       |15.500071441741781|\n",
      "|DOUT      |522876    |2850502       |15.500071441741781|\n",
      "|BROADBND  |385119    |2988259       |11.416419980209747|\n",
      "|HHLDRAGEP |181170    |3192208       |5.370581061476064 |\n",
      "|ACCESSINET|181170    |3192208       |5.370581061476064 |\n",
      "|VEH       |181170    |3192208       |5.370581061476064 |\n",
      "|DPHY      |155340    |3218038       |4.604879737758413 |\n",
      "|POVPIP    |153356    |3220022       |4.546066287264576 |\n",
      "|SCHL      |90621     |3282757       |2.686357710283283 |\n",
      "|YEAR      |0         |3373378       |0.0               |\n",
      "|ST        |0         |3373378       |0.0               |\n",
      "|SERIALNO  |0         |3373378       |0.0               |\n",
      "|SPORDER   |0         |3373378       |0.0               |\n",
      "|PWGTP     |0         |3373378       |0.0               |\n",
      "|AGEP      |0         |3373378       |0.0               |\n",
      "|SEX       |0         |3373378       |0.0               |\n",
      "|MAR       |0         |3373378       |0.0               |\n",
      "|HICOV     |0         |3373378       |0.0               |\n",
      "|HINS1     |0         |3373378       |0.0               |\n",
      "|HINS2     |0         |3373378       |0.0               |\n",
      "|HINS3     |0         |3373378       |0.0               |\n",
      "|HINS4     |0         |3373378       |0.0               |\n",
      "|HINS5     |0         |3373378       |0.0               |\n",
      "|HINS6     |0         |3373378       |0.0               |\n",
      "|DIS       |0         |3373378       |0.0               |\n",
      "+----------+----------+--------------+------------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "YEAR: 2023\n",
      "================================================================================\n",
      "Total rows in 2023: 3405809\n",
      "\n",
      "Null report per column for 2023\n",
      "+----------+----------+--------------+------------------+\n",
      "|column    |null_count|non_null_count|null_percent      |\n",
      "+----------+----------+--------------+------------------+\n",
      "|FER       |2688535   |717274        |78.93968804474942 |\n",
      "|INDP      |1371965   |2033844       |40.28308692589631 |\n",
      "|OCCP      |1371965   |2033844       |40.28308692589631 |\n",
      "|MIL       |599222    |2806587       |17.594116405235876|\n",
      "|ESR       |558164    |2847645       |16.388587850933508|\n",
      "|PINCP     |517377    |2888432       |15.191016290109047|\n",
      "|WAGP      |517377    |2888432       |15.191016290109047|\n",
      "|SEMP      |517377    |2888432       |15.191016290109047|\n",
      "|SSP       |517377    |2888432       |15.191016290109047|\n",
      "|RETP      |517377    |2888432       |15.191016290109047|\n",
      "|DOUT      |517377    |2888432       |15.191016290109047|\n",
      "|BROADBND  |360979    |3044830       |10.59892084377016 |\n",
      "|HHLDRAGEP |175965    |3229844       |5.166613864723477 |\n",
      "|ACCESSINET|175965    |3229844       |5.166613864723477 |\n",
      "|VEH       |175965    |3229844       |5.166613864723477 |\n",
      "|DPHY      |154157    |3251652       |4.526296101748513 |\n",
      "|POVPIP    |149883    |3255926       |4.400804625274054 |\n",
      "|SCHL      |90378     |3315431       |2.6536426440825074|\n",
      "|YEAR      |0         |3405809       |0.0               |\n",
      "|ST        |0         |3405809       |0.0               |\n",
      "|SERIALNO  |0         |3405809       |0.0               |\n",
      "|SPORDER   |0         |3405809       |0.0               |\n",
      "|PWGTP     |0         |3405809       |0.0               |\n",
      "|AGEP      |0         |3405809       |0.0               |\n",
      "|SEX       |0         |3405809       |0.0               |\n",
      "|MAR       |0         |3405809       |0.0               |\n",
      "|HICOV     |0         |3405809       |0.0               |\n",
      "|HINS1     |0         |3405809       |0.0               |\n",
      "|HINS2     |0         |3405809       |0.0               |\n",
      "|HINS3     |0         |3405809       |0.0               |\n",
      "|HINS4     |0         |3405809       |0.0               |\n",
      "|HINS5     |0         |3405809       |0.0               |\n",
      "|HINS6     |0         |3405809       |0.0               |\n",
      "|DIS       |0         |3405809       |0.0               |\n",
      "+----------+----------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "base_path = \"/s/chopin/b/grad/C837217249/project/parque_data\"\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "for year in years:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"YEAR: {year}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    path = f\"{base_path}/pums_{year}.parquet\"\n",
    "    df_y = spark.read.parquet(path)\n",
    "\n",
    "\n",
    "    total_rows = df_y.count()\n",
    "    print(f\"Total rows in {year}: {total_rows}\")\n",
    "\n",
    "    null_count_exprs = [\n",
    "        F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "        for c in df_y.columns\n",
    "    ]\n",
    "    null_counts_wide = df_y.agg(*null_count_exprs)\n",
    "\n",
    "\n",
    "    stack_expr = \"stack({n}, {pairs}) as (column, null_count)\".format(\n",
    "        n=len(df_y.columns),\n",
    "        pairs=\", \".join([f\"'{c}', `{c}`\" for c in df_y.columns])\n",
    "    )\n",
    "\n",
    "    nulls_long = null_counts_wide.selectExpr(stack_expr)\n",
    "\n",
    "\n",
    "    null_report = (\n",
    "        nulls_long\n",
    "        .withColumn(\"non_null_count\", F.lit(total_rows) - F.col(\"null_count\"))\n",
    "        .withColumn(\"null_percent\", (F.col(\"null_count\") / F.lit(total_rows)) * 100)\n",
    "        .orderBy(F.col(\"null_percent\").desc())\n",
    "    )\n",
    "\n",
    "    print(f\"\\nNull report per column for {year}\")\n",
    "    null_report.show(50, truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5857af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      "\n",
      "+----+---+-------------+-------+-----+----+---+---+---------+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----------+----+---+\n",
      "|YEAR| ST|     SERIALNO|SPORDER|PWGTP|AGEP|SEX|MAR|HHLDRAGEP|HICOV|HINS1|HINS2|HINS3|HINS4|HINS5|HINS6|POVPIP|PINCP|ESR| WAGP|SEMP|  SSP|RETP|SCHL|INDP|OCCP|DOUT|DPHY|DIS| FER|BROADBND|ACCESSINET| VEH|MIL|\n",
      "+----+---+-------------+-------+-----+----+---+---+---------+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----------+----+---+\n",
      "|2022| 49|2022GQ0000032|      1|   33|  66|  2|  3|     NULL|    1|    2|    2|    1|    1|    2|    2|  NULL|14500|  6|    0|   0|14500|   0|  16|NULL|NULL|   1|   1|  1|NULL|    NULL|      NULL|NULL|  4|\n",
      "|2022| 42|2022GQ0000063|      1|   29|  83|  1|  2|     NULL|    1|    1|    2|    1|    2|    2|    2|  NULL| 6500|  6|    0|   0| 6500|   0|  16|NULL|NULL|   1|   1|  1|NULL|    NULL|      NULL|NULL|  4|\n",
      "|2022| 54|2022GQ0000064|      1|   17|  21|  2|  5|     NULL|    1|    1|    2|    2|    1|    2|    2|  NULL| 5000|  3| 5000|   0|    0|   0|  19|9170|2002|   2|   2|  1|   2|    NULL|      NULL|NULL|  4|\n",
      "|2022| 42|2022GQ0000096|      1|   38|  73|  2|  3|     NULL|    1|    2|    2|    1|    1|    2|    2|  NULL|16400|  6|    0|   0|16400|   0|  16|NULL|NULL|   1|   2|  1|NULL|    NULL|      NULL|NULL|  4|\n",
      "|2022| 32|2022GQ0000107|      1|   84|  20|  1|  5|     NULL|    1|    2|    2|    2|    1|    2|    2|  NULL|35000|  6|35000|   0|    0|   0|  14|8680|4020|   2|   2|  2|NULL|    NULL|      NULL|NULL|  4|\n",
      "+----+---+-------------+-------+-----+----+---+---+---------+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----------+----+---+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "path_2022 = \"/s/chopin/b/grad/C837217249/project/parque_data/pums_2022.parquet\"\n",
    "df22 = spark.read.parquet(path_2022)\n",
    "\n",
    "df22.printSchema()\n",
    "df22.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dbc74dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              AGEP|\n",
      "+-------+------------------+\n",
      "|  count|           3373378|\n",
      "|   mean|42.768076687522125|\n",
      "| stddev| 23.90890709761891|\n",
      "|    min|                 0|\n",
      "|    max|                97|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df22.describe(\"AGEP\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfe1f1",
   "metadata": {},
   "source": [
    "# Target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28fb5aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /s/chopin/b/grad/C837217249/project/target_Datasets/Table_2019.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /s/chopin/b/grad/C837217249/project/target_Datasets/Table_2020.csv ...\n",
      "Loading /s/chopin/b/grad/C837217249/project/target_Datasets/Table_2021.csv ...\n",
      "Loading /s/chopin/b/grad/C837217249/project/target_Datasets/Table_2022.csv ...\n",
      "Loading /s/chopin/b/grad/C837217249/project/target_Datasets/Table_2023.csv ...\n",
      "Combined target row count: 255\n",
      "+----+---+--------------------+-------+\n",
      "|YEAR|ST |STATE_NAME          |PCE_PC |\n",
      "+----+---+--------------------+-------+\n",
      "|2019|1  |Alabama             |6267.0 |\n",
      "|2019|2  |Alaska              |10777.0|\n",
      "|2019|4  |Arizona             |6444.0 |\n",
      "|2019|5  |Arkansas            |6606.0 |\n",
      "|2019|6  |California          |8218.0 |\n",
      "|2019|8  |Colorado            |7024.0 |\n",
      "|2019|9  |Connecticut         |8420.0 |\n",
      "|2019|10 |Delaware            |9079.0 |\n",
      "|2019|11 |District of Columbia|10997.0|\n",
      "|2019|12 |Florida             |7216.0 |\n",
      "|2019|13 |Georgia             |6365.0 |\n",
      "|2019|15 |Hawaii              |7318.0 |\n",
      "|2019|16 |Idaho               |6050.0 |\n",
      "|2019|17 |Illinois            |7355.0 |\n",
      "|2019|18 |Indiana             |7998.0 |\n",
      "|2019|19 |Iowa                |7025.0 |\n",
      "|2019|20 |Kansas              |6981.0 |\n",
      "|2019|21 |Kentucky            |7188.0 |\n",
      "|2019|22 |Louisiana           |7215.0 |\n",
      "|2019|23 |Maine               |8810.0 |\n",
      "|2019|24 |Maryland            |7560.0 |\n",
      "|2019|25 |Massachusetts       |9650.0 |\n",
      "|2019|26 |Michigan            |7275.0 |\n",
      "|2019|27 |Minnesota           |8407.0 |\n",
      "|2019|28 |Mississippi         |6400.0 |\n",
      "|2019|29 |Missouri            |7577.0 |\n",
      "|2019|30 |Montana             |7960.0 |\n",
      "|2019|31 |Nebraska            |7828.0 |\n",
      "|2019|32 |Nevada              |6211.0 |\n",
      "|2019|33 |New Hampshire       |8837.0 |\n",
      "|2019|34 |New Jersey          |8008.0 |\n",
      "|2019|35 |New Mexico          |6413.0 |\n",
      "|2019|36 |New York            |8925.0 |\n",
      "|2019|37 |North Carolina      |6636.0 |\n",
      "|2019|38 |North Dakota        |9514.0 |\n",
      "|2019|39 |Ohio                |8156.0 |\n",
      "|2019|40 |Oklahoma            |6685.0 |\n",
      "|2019|41 |Oregon              |7622.0 |\n",
      "|2019|42 |Pennsylvania        |8311.0 |\n",
      "|2019|44 |Rhode Island        |7935.0 |\n",
      "|2019|45 |South Carolina      |6020.0 |\n",
      "|2019|46 |South Dakota        |9912.0 |\n",
      "|2019|47 |Tennessee           |6711.0 |\n",
      "|2019|48 |Texas               |6166.0 |\n",
      "|2019|49 |Utah                |5547.0 |\n",
      "|2019|50 |Vermont             |9087.0 |\n",
      "|2019|51 |Virginia            |6706.0 |\n",
      "|2019|53 |Washington          |7569.0 |\n",
      "|2019|54 |West Virginia       |9030.0 |\n",
      "|2019|55 |Wisconsin           |8137.0 |\n",
      "|2019|56 |Wyoming             |7739.0 |\n",
      "|2020|1  |Alabama             |5983.0 |\n",
      "|2020|2  |Alaska              |9751.0 |\n",
      "|2020|4  |Arizona             |6275.0 |\n",
      "|2020|5  |Arkansas            |6312.0 |\n",
      "|2020|6  |California          |7820.0 |\n",
      "|2020|8  |Colorado            |6562.0 |\n",
      "|2020|9  |Connecticut         |8121.0 |\n",
      "|2020|10 |Delaware            |8539.0 |\n",
      "|2020|11 |District of Columbia|10542.0|\n",
      "+----+---+--------------------+-------+\n",
      "only showing top 60 rows\n",
      "root\n",
      " |-- YEAR: integer (nullable = false)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- PCE_PC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Merge_PUMS_and_Targets\").getOrCreate()\n",
    "\n",
    "targets_base = \"/s/chopin/b/grad/C837217249/project/target_Datasets\"\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "state_names = [\n",
    "    \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\n",
    "    \"Delaware\",\"District of Columbia\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "    \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\n",
    "    \"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\n",
    "    \"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\n",
    "    \"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\"South Carolina\",\n",
    "    \"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\n",
    "    \"West Virginia\",\"Wisconsin\",\"Wyoming\",\n",
    "]\n",
    "\n",
    "def load_target(year: int):\n",
    "    path = os.path.join(targets_base, f\"Table_{year}.csv\")\n",
    "    print(f\"Loading {path} ...\")\n",
    "\n",
    "    raw = spark.read.text(path)\n",
    "\n",
    "    body_rdd = (\n",
    "        raw.rdd\n",
    "           .zipWithIndex()\n",
    "           .filter(lambda x: x[1] >= 3)      \n",
    "           .map(lambda x: x[0][0])\n",
    "    )\n",
    "\n",
    "    df = spark.read.csv(body_rdd, header=True, inferSchema=False)\n",
    "\n",
    "    df = df.filter(F.col(\"GeoFips\").rlike(r\"^[0-9]+$\"))\n",
    "\n",
    "    df = df.withColumn(\"GeoFips_int\", F.col(\"GeoFips\").cast(\"int\"))\n",
    "    df = df.filter(F.col(\"GeoFips_int\").isNotNull())\n",
    "    df = df.filter(F.col(\"GeoFips_int\") != 0)\n",
    "\n",
    "    df = df.filter(F.col(\"GeoName\").isin(state_names))\n",
    "\n",
    "    df = df.withColumn(\"ST\", (F.col(\"GeoFips_int\") / 1000).cast(\"int\"))\n",
    "\n",
    "    value_col_name = str(year)\n",
    "    df = df.withColumn(\"YEAR\", F.lit(year))\n",
    "    df = df.withColumn(\"PCE_PC\", F.col(value_col_name).cast(\"double\"))\n",
    "\n",
    "    df = df.select(\n",
    "        \"YEAR\",\n",
    "        \"ST\",\n",
    "        F.col(\"GeoName\").alias(\"STATE_NAME\"),\n",
    "        \"PCE_PC\"\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "df_target_all = None\n",
    "for y in years:\n",
    "    df_y = load_target(y)\n",
    "    if df_target_all is None:\n",
    "        df_target_all = df_y\n",
    "    else:\n",
    "        df_target_all = df_target_all.unionByName(df_y)\n",
    "\n",
    "print(\"Combined target row count:\", df_target_all.count())\n",
    "df_target_all.orderBy(\"YEAR\", \"ST\").show(60, truncate=False)\n",
    "df_target_all.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c3353a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PUMS parquet for 2019: /s/chopin/b/grad/C837217249/project/parque_data/pums_2019.parquet\n",
      "Reading PUMS parquet for 2020: /s/chopin/b/grad/C837217249/project/parque_data/pums_2020.parquet\n",
      "Reading PUMS parquet for 2021: /s/chopin/b/grad/C837217249/project/parque_data/pums_2021.parquet\n",
      "Reading PUMS parquet for 2022: /s/chopin/b/grad/C837217249/project/parque_data/pums_2022.parquet\n",
      "Reading PUMS parquet for 2023: /s/chopin/b/grad/C837217249/project/parque_data/pums_2023.parquet\n",
      "Total PUMS rows (all years): 15912393\n",
      "Number of columns: 34\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "parquet_base = \"/s/chopin/b/grad/C837217249/project/parque_data\"\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "dfs = []\n",
    "for y in years:\n",
    "    path = f\"{parquet_base}/pums_{y}.parquet\"\n",
    "    print(f\"Reading PUMS parquet for {y}: {path}\")\n",
    "    \n",
    "    df_y = spark.read.parquet(path)\n",
    "\n",
    "\n",
    "    if \"YEAR\" not in df_y.columns:\n",
    "        df_y = df_y.withColumn(\"YEAR\", F.lit(y))\n",
    "    else:\n",
    "\n",
    "        df_y = df_y.withColumn(\"YEAR\", F.col(\"YEAR\").cast(\"int\"))\n",
    "\n",
    "    dfs.append(df_y)\n",
    "\n",
    "\n",
    "df_pums_all = reduce(\n",
    "    lambda a, b: a.unionByName(b, allowMissingColumns=True),\n",
    "    dfs\n",
    ")\n",
    "\n",
    "print(\"Total PUMS rows (all years):\", df_pums_all.count())\n",
    "print(\"Number of columns:\", len(df_pums_all.columns))\n",
    "df_pums_all.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1b5318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target rows: 255\n",
      "Joined rows: 15912393\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- TOTAL_HEALTH_SPENDING: double (nullable = true)\n",
      "\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----+----+----------+---------+--------------+---------------------+\n",
      "|YEAR| ST|     SERIALNO|SPORDER|PWGTP|AGEP|SEX|MAR|HICOV|HINS1|HINS2|HINS3|HINS4|HINS5|HINS6|POVPIP|PINCP|ESR| WAGP|SEMP|  SSP|RETP|SCHL|INDP|OCCP|DOUT|DPHY|DIS| FER|BROADBND| VEH| MIL|ACCESSINET|HHLDRAGEP|    STATE_NAME|TOTAL_HEALTH_SPENDING|\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----+----+----------+---------+--------------+---------------------+\n",
      "|2019| 28|2019GQ0000018|      1|    8|  58|  1|  5|    1|    2|    2|    1|    1|    2|    2|   279|36500|  1|28000|   0| 8500|   0|  17|5381|4965|   1|   2|  1|NULL|    NULL|NULL|   4|      NULL|     NULL|   Mississippi|               6400.0|\n",
      "|2019| 51|2019GQ0000025|      1|   52|  19|  1|  5|    1|    1|    2|    2|    2|    2|    2|  NULL|    0|  6|    0|   0|    0|   0|  16|NULL|NULL|   2|   2|  2|NULL|    NULL|NULL|   4|      NULL|     NULL|      Virginia|               6706.0|\n",
      "|2019| 25|2019GQ0000052|      1|   11|  16|  1|  5|    1|    2|    2|    2|    1|    2|    2|  NULL|    0|  6|    0|   0|    0|   0|  12|NULL|NULL|   2|   2|  1|NULL|    NULL|NULL|NULL|      NULL|     NULL| Massachusetts|               9650.0|\n",
      "|2019| 45|2019GQ0000062|      1|   60|  81|  1|  1|    1|    2|    2|    1|    1|    2|    2|  NULL|14500|  6|    0|   0|14500|   0|  19|NULL|NULL|   1|   1|  1|NULL|    NULL|NULL|   4|      NULL|     NULL|South Carolina|               6020.0|\n",
      "|2019| 47|2019GQ0000076|      1|   35|  86|  1|  3|    1|    2|    2|    1|    1|    2|    2|  NULL|21300|  6|    0|   0|21300|   0|  16|NULL|NULL|   1|   1|  1|NULL|    NULL|NULL|   4|      NULL|     NULL|     Tennessee|               6711.0|\n",
      "+----+---+-------------+-------+-----+----+---+---+-----+-----+-----+-----+-----+-----+-----+------+-----+---+-----+----+-----+----+----+----+----+----+----+---+----+--------+----+----+----------+---------+--------------+---------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_target_all = df_target_all.withColumnRenamed(\"PCE_PC\", \"TOTAL_HEALTH_SPENDING\")\n",
    "\n",
    "\n",
    "df_target_small = df_target_all.select(\"YEAR\", \"ST\", \"STATE_NAME\", \"TOTAL_HEALTH_SPENDING\")\n",
    "\n",
    "print(\"Target rows:\", df_target_small.count())\n",
    "\n",
    "\n",
    "df_pums_with_target = (\n",
    "    df_pums_all\n",
    "    .join(F.broadcast(df_target_small), on=[\"YEAR\", \"ST\"], how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Joined rows:\", df_pums_with_target.count())\n",
    "df_pums_with_target.printSchema()\n",
    "df_pums_with_target.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e746c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f146a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing year 2019 to /s/chopin/b/grad/C837217249/project/complete/pums_2019.parquet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:38 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing year 2020 to /s/chopin/b/grad/C837217249/project/complete/pums_2020.parquet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing year 2021 to /s/chopin/b/grad/C837217249/project/complete/pums_2021.parquet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing year 2022 to /s/chopin/b/grad/C837217249/project/complete/pums_2022.parquet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing year 2023 to /s/chopin/b/grad/C837217249/project/complete/pums_2023.parquet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/30 09:21:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/30 09:21:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/30 09:21:50 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing per-year Parquet datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 54:==============================================>       (90 + 15) / 105]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "out_base = \"/s/chopin/b/grad/C837217249/project/complete\"\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "for y in years:\n",
    "    out_path = f\"{out_base}/pums_{y}.parquet\"\n",
    "    print(f\"Writing year {y} to {out_path} ...\")\n",
    "    \n",
    "    (\n",
    "        df_pums_with_target\n",
    "        .filter(F.col(\"YEAR\") == y)\n",
    "\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(out_path)\n",
    "    )\n",
    "\n",
    "print(\"Done writing per-year Parquet datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37af9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in 2022 parquet: 3373378\n",
      "Columns: 36\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- TOTAL_HEALTH_SPENDING: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_2022 = \"/s/chopin/b/grad/C837217249/project/complete/pums_2022.parquet\"\n",
    "\n",
    "df22 = spark.read.parquet(path_2022)\n",
    "\n",
    "print(\"Rows in 2022 parquet:\", df22.count())\n",
    "print(\"Columns:\", len(df22.columns))\n",
    "df22.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6a37e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in 2022 parquet: 3373378\n",
      "Columns: 36\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- TOTAL_HEALTH_SPENDING: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_base = \"/s/chopin/b/grad/C837217249/project/complete\"\n",
    "path_2022 = f\"{out_base}/pums_2022.parquet\"\n",
    "\n",
    "df22 = spark.read.parquet(path_2022)\n",
    "\n",
    "print(\"Rows in 2022 parquet:\", df22.count())\n",
    "print(\"Columns:\", len(df22.columns))\n",
    "df22.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4201425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------+---------------------+\n",
      "|YEAR|ST |STATE_NAME    |TOTAL_HEALTH_SPENDING|\n",
      "+----+---+--------------+---------------------+\n",
      "|2022|49 |Utah          |6291.0               |\n",
      "|2022|42 |Pennsylvania  |9052.0               |\n",
      "|2022|54 |West Virginia |10186.0              |\n",
      "|2022|42 |Pennsylvania  |9052.0               |\n",
      "|2022|32 |Nevada        |6814.0               |\n",
      "|2022|42 |Pennsylvania  |9052.0               |\n",
      "|2022|32 |Nevada        |6814.0               |\n",
      "|2022|36 |New York      |10274.0              |\n",
      "|2022|36 |New York      |10274.0              |\n",
      "|2022|51 |Virginia      |7695.0               |\n",
      "|2022|39 |Ohio          |8874.0               |\n",
      "|2022|1  |Alabama       |7125.0               |\n",
      "|2022|13 |Georgia       |7385.0               |\n",
      "|2022|17 |Illinois      |8445.0               |\n",
      "|2022|48 |Texas         |6878.0               |\n",
      "|2022|12 |Florida       |8254.0               |\n",
      "|2022|39 |Ohio          |8874.0               |\n",
      "|2022|36 |New York      |10274.0              |\n",
      "|2022|4  |Arizona       |7311.0               |\n",
      "|2022|6  |California    |9457.0               |\n",
      "|2022|12 |Florida       |8254.0               |\n",
      "|2022|17 |Illinois      |8445.0               |\n",
      "|2022|6  |California    |9457.0               |\n",
      "|2022|24 |Maryland      |8233.0               |\n",
      "|2022|4  |Arizona       |7311.0               |\n",
      "|2022|15 |Hawaii        |8352.0               |\n",
      "|2022|1  |Alabama       |7125.0               |\n",
      "|2022|45 |South Carolina|6769.0               |\n",
      "|2022|17 |Illinois      |8445.0               |\n",
      "|2022|36 |New York      |10274.0              |\n",
      "+----+---+--------------+---------------------+\n",
      "only showing top 30 rows\n"
     ]
    }
   ],
   "source": [
    "df22.select(\"YEAR\", \"ST\", \"STATE_NAME\", \"TOTAL_HEALTH_SPENDING\").show(30, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a75ff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PUMS+target parquet for 2019: /s/chopin/b/grad/C837217249/project/complete/pums_2019.parquet\n",
      "Reading PUMS+target parquet for 2020: /s/chopin/b/grad/C837217249/project/complete/pums_2020.parquet\n",
      "Reading PUMS+target parquet for 2021: /s/chopin/b/grad/C837217249/project/complete/pums_2021.parquet\n",
      "Reading PUMS+target parquet for 2022: /s/chopin/b/grad/C837217249/project/complete/pums_2022.parquet\n",
      "Reading PUMS+target parquet for 2023: /s/chopin/b/grad/C837217249/project/complete/pums_2023.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/30 09:22:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total micro rows (all years): 15912393\n",
      "Columns: 36\n",
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- SERIALNO: string (nullable = true)\n",
      " |-- SPORDER: integer (nullable = true)\n",
      " |-- PWGTP: integer (nullable = true)\n",
      " |-- AGEP: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- MAR: integer (nullable = true)\n",
      " |-- HICOV: integer (nullable = true)\n",
      " |-- HINS1: integer (nullable = true)\n",
      " |-- HINS2: integer (nullable = true)\n",
      " |-- HINS3: integer (nullable = true)\n",
      " |-- HINS4: integer (nullable = true)\n",
      " |-- HINS5: integer (nullable = true)\n",
      " |-- HINS6: integer (nullable = true)\n",
      " |-- POVPIP: integer (nullable = true)\n",
      " |-- PINCP: integer (nullable = true)\n",
      " |-- ESR: integer (nullable = true)\n",
      " |-- WAGP: integer (nullable = true)\n",
      " |-- SEMP: integer (nullable = true)\n",
      " |-- SSP: integer (nullable = true)\n",
      " |-- RETP: integer (nullable = true)\n",
      " |-- SCHL: integer (nullable = true)\n",
      " |-- INDP: integer (nullable = true)\n",
      " |-- OCCP: integer (nullable = true)\n",
      " |-- DOUT: integer (nullable = true)\n",
      " |-- DPHY: integer (nullable = true)\n",
      " |-- DIS: integer (nullable = true)\n",
      " |-- FER: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- MIL: integer (nullable = true)\n",
      " |-- ACCESSINET: integer (nullable = true)\n",
      " |-- HHLDRAGEP: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- TOTAL_HEALTH_SPENDING: double (nullable = true)\n",
      "\n",
      "State-year rows (should be ~250–255): 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "|YEAR|ST |STATE_NAME          |TOTAL_HEALTH_SPENDING|AGEP_65plus_share  |AGEP_0_17_share    |SEX_female_share  |MAR_ever_married_share|HICOV_uninsured_share|HINS1_employer_share|HINS2_direct_share |HINS3_medicare_share|HINS4_medicaid_share|HINS5_tricare_share |HINS6_va_share      |POVPIP_lt138_share |PINCP_mean        |WAGP_mean         |SEMP_mean_if_positive|SSP_per_capita    |RETP_positive_share|ESR_unemp_or_nilf_share|ESR_in_labor_force_share|SCHL_bach_plus_share|DOUT_diff_share     |DPHY_diff_share     |DIS_any_share      |FER_births_per_1000_women_15_50|BROADBND_yes_share|VEH_mean_per_person|MIL_veteran_share   |MIL_active_duty_share|\n",
      "+----+---+--------------------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "|2019|1  |Alabama             |6267.0               |0.17420717350048998|0.2215276396872645 |0.5159356622277153|0.5479921724348561    |0.10098170882803728  |0.5333119186814285  |0.13236192393311694|0.2088142707240294  |0.19599933512604562 |0.05172433836373704 |0.027720553069076528|0.22397115344413887|28160.502641446325|19891.79276531479 |32417.354083587965   |2763.078986413933 |0.12211756235997621|0.3607357258598238     |0.4651158379706252      |0.18742715194307374 |0.06124631234595472 |0.0919398309466194  |0.16562438496609858|51.43216049588196              |0.7700413098832698|2.2044993203397385 |0.07959499794521316 |0.003445107618823275 |\n",
      "|2019|2  |Alaska              |10777.0              |0.12736332009650808|0.24383189004094075|0.482634697797128 |0.5112453779330048    |0.11482137120751287  |0.5510583764498425  |0.07580121523624657|0.13653568816682501 |0.21025910914571216 |0.12886425305346902 |0.044991080521362324|0.15571427595021495|36067.735409304965|25936.937823373817|29700.139058059278   |1705.404561578577 |0.10492724302674476|0.2966639099440226     |0.5092277303515164      |0.20978613755818165 |0.03408129370031919 |0.05322707420596136 |0.11599423138699602|63.6943061058805               |0.8122220779309544|2.0237374324204254 |0.09465993206159566 |0.02441134858416092  |\n",
      "|2019|4  |Arizona             |6444.0               |0.1794148611630319 |0.225106842318502  |0.5022475801710659|0.52492369190889      |0.11713328049435086  |0.5000379874639995  |0.12432877937141944|0.19611684311946734 |0.21027799267370884 |0.03579861670676302 |0.02944131500098163 |0.19214883612043165|31789.02199041397 |22242.152430160426|34913.60057111129    |2738.600812478353 |0.12058828499583099|0.34301828193073036    |0.4805383970828925      |0.21443998990481428 |0.04619935079217945 |0.06615341687278128 |0.13329230961995087|53.440942765649986             |0.7964131590773483|2.146603858894363  |0.07499563453284418 |0.003178719546315649 |\n",
      "|2019|5  |Arkansas            |6606.0               |0.17306558013707982|0.23148620652633503|0.5115709966584974|0.5584855742785151    |0.09603937167556276  |0.46428992737765606 |0.1285421452155276 |0.2086745858909326  |0.26479817774779274 |0.032998166878962315|0.03248454836695822 |0.24122905264887978|26926.346112272367|19013.43031555396 |30170.524638457417   |2687.262244333959 |0.10813989245159726|0.3536846660684392     |0.4647011535540413      |0.16507831522524324 |0.06683899948439329 |0.10063874260886393 |0.18015318423595436|54.0839042573386               |0.7540241181998566|2.073541224015874  |0.07467781207792157 |0.0022715192901858437|\n",
      "|2019|6  |California          |8218.0               |0.1476852112319775 |0.2247371402008943 |0.5027187662916359|0.49412681741546155   |0.07953652721589469  |0.5250220166048364  |0.11989581046857323|0.15724268411827905 |0.25615463346620615 |0.02081631802898055 |0.014900933313724211|0.173582513947646  |39076.37701467721 |29269.93172264694 |42880.90672105757    |1896.7513796933167|0.08813951065218477|0.3134100047977559     |0.5131628002808144      |0.249605444877146   |0.0451796903454407  |0.056417099083491205|0.1091148174578788 |46.749769648568844             |0.8441916315363982|2.2916836392627165 |0.043255829974436014|0.003589901788112504 |\n",
      "|2019|8  |Colorado            |7024.0               |0.14713072452010303|0.21768179683875072|0.4950787811769805|0.5488372795696833    |0.08063488237696606  |0.5711654432500466  |0.13261712292419725|0.15728711995132266 |0.17011649778701438 |0.04646245287160238 |0.025941803895854924|0.13653464927025652|40757.37190140336 |30539.33460398254 |36946.0218817188     |2017.6421388304657|0.1048915942665196 |0.272968929292817      |0.554659216883705       |0.308488529427291   |0.03789512142942479 |0.04935840087130231 |0.10911092295253681|44.583379558883                |0.8535746386012486|2.2711567260593295 |0.0719965284048444  |0.005990203405747373 |\n",
      "|2019|9  |Connecticut         |8420.0               |0.17679698717101877|0.20402957742251887|0.5107647715317168|0.5263806251782815    |0.05868952485452083  |0.5888594662926154  |0.1195348368869042 |0.188278250811225   |0.21992787677401568 |0.015323591060130643|0.015445039908428129|0.14340809028838353|45216.16464284642 |33723.916660846655|47429.93025407762    |2758.109403254212 |0.11745758476105851|0.3060797069071859     |0.544953884497938       |0.29686586241163754 |0.04990453783945023 |0.06145760495578617 |0.12384472834865748|38.01813670867373              |0.815311642512931 |2.0129434180193626 |0.05297077065605097 |0.002552669672876265 |\n",
      "|2019|10 |Delaware            |9079.0               |0.19418770872613897|0.20944807982221564|0.5153137721254842|0.5451659745071701    |0.07166828923640636  |0.585845235601234   |0.13580908721209656|0.21363697980208757 |0.20520885964155586 |0.0486390953044064  |0.024287198951696714|0.14976832168780116|37235.41339585362 |26116.57107882403 |37535.15388969997    |3127.347211439322 |0.16558324193541762|0.3284009267132488     |0.5067654996487856      |0.24818847277163666 |0.047505350372369484|0.0675153322570972  |0.13873382051503239|37.13563527583888              |0.8468129854872433|2.079083843723941  |0.08730041365258934 |0.005718017918099252 |\n",
      "|2019|11 |District of Columbia|10997.0              |0.12425664081706102|0.18091701157210283|0.5239950747362022|0.3469547955434581    |0.03672693833076632  |0.604644144022875   |0.12910539015995773|0.13481705252150553 |0.248826424125291   |0.02664119963329739 |0.015487092436546137|0.1755482473230568 |58938.58800791783 |47392.4256470785  |53747.16014609385    |1442.1214057689065|0.08887012238061974|0.2838572920400879     |0.5871081645174134      |0.4530973476405918  |0.048980586582481875|0.06446767901902802 |0.11905365788686913|39.42706087478206              |0.8138715038916102|1.0462473202229121 |0.04165645293156632 |0.0038767323793586672|\n",
      "|2019|12 |Florida             |7216.0               |0.20939324287284083|0.1969733589716645 |0.5111113894354885|0.5514338405391592    |0.13571159754866166  |0.4514539404221218  |0.16751895229930416|0.22630428894813268 |0.17512738888645485 |0.03913461646355014 |0.028883862392020166|0.19248680622171693|32644.372712032   |21987.104591885076|35410.76371237552    |3021.2695783545537|0.12420642826569671|0.3579261632638485     |0.4895014311796443      |0.23013253211918927 |0.05215600693871985 |0.07559483571290589 |0.14037181850210756|42.961344388953506             |0.8080848554947851|1.978464677167804  |0.0746633129924256  |0.003198102295414084 |\n",
      "+----+---+--------------------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:===================================================>  (100 + 5) / 105]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State-level panel saved to: /s/chopin/b/grad/C837217249/project/final_state_panel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StateLevel_HealthSpending_Panel\").getOrCreate()\n",
    "\n",
    "\n",
    "parquet_base = \"/s/chopin/b/grad/C837217249/project/complete\"\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "dfs = []\n",
    "for y in years:\n",
    "    path = f\"{parquet_base}/pums_{y}.parquet\"\n",
    "    print(f\"Reading PUMS+target parquet for {y}: {path}\")\n",
    "    \n",
    "    df_y = spark.read.parquet(path)\n",
    "\n",
    "    if \"YEAR\" not in df_y.columns:\n",
    "        df_y = df_y.withColumn(\"YEAR\", F.lit(y))\n",
    "    else:\n",
    "        df_y = df_y.withColumn(\"YEAR\", F.col(\"YEAR\").cast(\"int\"))\n",
    "\n",
    "    dfs.append(df_y)\n",
    "\n",
    "\n",
    "df_all = reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), dfs)\n",
    "\n",
    "print(\"Total micro rows (all years):\", df_all.count())\n",
    "print(\"Columns:\", len(df_all.columns))\n",
    "df_all.printSchema()\n",
    "\n",
    "#  Aggregating to state–year weighted sums\n",
    "group_cols = [\"YEAR\", \"ST\"]\n",
    "\n",
    "agg = (\n",
    "    df_all\n",
    "    .groupBy(*group_cols)\n",
    "    .agg(\n",
    "        # ID\n",
    "        F.first(\"STATE_NAME\").alias(\"STATE_NAME\"),\n",
    "        F.first(\"TOTAL_HEALTH_SPENDING\").alias(\"TOTAL_HEALTH_SPENDING\"),\n",
    "\n",
    "        # Total weighted population\n",
    "        F.sum(\"PWGTP\").alias(\"wt_pop\"),\n",
    "\n",
    "        # Age\n",
    "        F.sum(F.when(F.col(\"AGEP\") >= 65, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_age_65_plus\"),\n",
    "        F.sum(F.when(F.col(\"AGEP\") <= 17, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_age_0_17\"),\n",
    "\n",
    "        # Sex\n",
    "        F.sum(F.when(F.col(\"SEX\") == 2, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_female\"),\n",
    "\n",
    "        # Marital status\n",
    "        F.sum(F.when(F.col(\"MAR\").isin(1, 2, 3), F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_ever_married\"),\n",
    "\n",
    "        # Insurance coverage\n",
    "        F.sum(F.when(F.col(\"HICOV\") == 2, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_uninsured\"),\n",
    "\n",
    "        F.sum(F.when(F.col(\"HINS1\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins1_employer\"),\n",
    "        F.sum(F.when(F.col(\"HINS2\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins2_direct\"),\n",
    "        F.sum(F.when(F.col(\"HINS3\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins3_medicare\"),\n",
    "        F.sum(F.when(F.col(\"HINS4\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins4_medicaid\"),\n",
    "        F.sum(F.when(F.col(\"HINS5\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins5_tricare\"),\n",
    "        F.sum(F.when(F.col(\"HINS6\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_hins6_va\"),\n",
    "\n",
    "        # Poverty\n",
    "        F.sum(F.when(F.col(\"POVPIP\") < 138, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_pov_lt138\"),\n",
    "\n",
    "        # Income & transfers\n",
    "        F.sum(F.col(\"PWGTP\") * F.col(\"PINCP\")).alias(\"wt_sum_pincome\"),\n",
    "        F.sum(F.col(\"PWGTP\") * F.col(\"WAGP\")).alias(\"wt_sum_wagp\"),\n",
    "\n",
    "        F.sum(F.col(\"PWGTP\") * F.col(\"SEMP\")).alias(\"wt_sum_semp\"),\n",
    "        F.sum(F.when(F.col(\"SEMP\") > 0, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_semp_positive\"),\n",
    "\n",
    "        F.sum(F.col(\"PWGTP\") * F.col(\"SSP\")).alias(\"wt_sum_ssp\"),\n",
    "        F.sum(F.when(F.col(\"RETP\") > 0, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_ret_income_any\"),\n",
    "\n",
    "        # Labor force\n",
    "        F.sum(F.when(F.col(\"ESR\").isin(3, 6), F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_esr_unemp_or_nilf\"),\n",
    "        F.sum(F.when(F.col(\"ESR\").isin(1, 2, 3, 4, 5), F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_in_labor_force\"),\n",
    "\n",
    "        # Education\n",
    "        F.sum(F.when(F.col(\"SCHL\") >= 21, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_bach_plus\"),\n",
    "\n",
    "        # Disability\n",
    "        F.sum(F.when(F.col(\"DOUT\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_dout_diff\"),\n",
    "        F.sum(F.when(F.col(\"DPHY\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_dphy_diff\"),\n",
    "        F.sum(F.when(F.col(\"DIS\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_disabled_any\"),\n",
    "\n",
    "        # Fertility\n",
    "        F.sum(\n",
    "            F.when(\n",
    "                (F.col(\"SEX\") == 2) & (F.col(\"AGEP\").between(15, 50)) & (F.col(\"FER\") == 1),\n",
    "                F.col(\"PWGTP\")\n",
    "            ).otherwise(0)\n",
    "        ).alias(\"wt_births_women_15_50\"),\n",
    "        F.sum(\n",
    "            F.when(\n",
    "                (F.col(\"SEX\") == 2) & (F.col(\"AGEP\").between(15, 50)),\n",
    "                F.col(\"PWGTP\")\n",
    "            ).otherwise(0)\n",
    "        ).alias(\"wt_women_15_50\"),\n",
    "\n",
    "        # Broadband / access\n",
    "        F.sum(F.when(F.col(\"BROADBND\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_broadband_yes\"),\n",
    "\n",
    "        # Vehicles\n",
    "        F.sum(F.col(\"PWGTP\") * F.col(\"VEH\")).alias(\"wt_sum_veh\"),\n",
    "\n",
    "        # Military\n",
    "        F.sum(F.when(F.col(\"MIL\").isin(2, 3), F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_veterans\"),\n",
    "        F.sum(F.when(F.col(\"MIL\") == 1, F.col(\"PWGTP\")).otherwise(0)).alias(\"wt_active_duty\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "#  Turning weighted sums into per-capita\n",
    "features = (\n",
    "    agg\n",
    "    .withColumn(\"AGEP_65plus_share\",       F.col(\"wt_age_65_plus\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"AGEP_0_17_share\",         F.col(\"wt_age_0_17\")     / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"SEX_female_share\",        F.col(\"wt_female\")       / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"MAR_ever_married_share\",  F.col(\"wt_ever_married\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\"HICOV_uninsured_share\",   F.col(\"wt_uninsured\")      / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS1_employer_share\",    F.col(\"wt_hins1_employer\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS2_direct_share\",      F.col(\"wt_hins2_direct\")   / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS3_medicare_share\",    F.col(\"wt_hins3_medicare\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS4_medicaid_share\",    F.col(\"wt_hins4_medicaid\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS5_tricare_share\",     F.col(\"wt_hins5_tricare\")  / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"HINS6_va_share\",          F.col(\"wt_hins6_va\")       / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\"POVPIP_lt138_share\",      F.col(\"wt_pov_lt138\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"PINCP_mean\",              F.col(\"wt_sum_pincome\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"WAGP_mean\",               F.col(\"wt_sum_wagp\")    / F.col(\"wt_pop\"))\n",
    "    .withColumn(\n",
    "        \"SEMP_mean_if_positive\",\n",
    "        F.when(F.col(\"wt_semp_positive\") > 0,\n",
    "               F.col(\"wt_sum_semp\") / F.col(\"wt_semp_positive\")\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "    .withColumn(\"SSP_per_capita\",          F.col(\"wt_sum_ssp\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"RETP_positive_share\",     F.col(\"wt_ret_income_any\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\"ESR_unemp_or_nilf_share\", F.col(\"wt_esr_unemp_or_nilf\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"ESR_in_labor_force_share\",F.col(\"wt_in_labor_force\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\"SCHL_bach_plus_share\",    F.col(\"wt_bach_plus\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\"DOUT_diff_share\",         F.col(\"wt_dout_diff\")    / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"DPHY_diff_share\",         F.col(\"wt_dphy_diff\")    / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"DIS_any_share\",           F.col(\"wt_disabled_any\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .withColumn(\n",
    "        \"FER_births_per_1000_women_15_50\",\n",
    "        F.when(F.col(\"wt_women_15_50\") > 0,\n",
    "               1000.0 * F.col(\"wt_births_women_15_50\") / F.col(\"wt_women_15_50\")\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "    .withColumn(\"BROADBND_yes_share\",      F.col(\"wt_broadband_yes\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"VEH_mean_per_person\",     F.col(\"wt_sum_veh\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"MIL_veteran_share\",       F.col(\"wt_veterans\") / F.col(\"wt_pop\"))\n",
    "    .withColumn(\"MIL_active_duty_share\",   F.col(\"wt_active_duty\") / F.col(\"wt_pop\"))\n",
    "\n",
    "    .select(\n",
    "        \"YEAR\", \"ST\", \"STATE_NAME\", \"TOTAL_HEALTH_SPENDING\",\n",
    "        \"AGEP_65plus_share\", \"AGEP_0_17_share\", \"SEX_female_share\",\n",
    "        \"MAR_ever_married_share\",\n",
    "        \"HICOV_uninsured_share\",\n",
    "        \"HINS1_employer_share\", \"HINS2_direct_share\",\n",
    "        \"HINS3_medicare_share\", \"HINS4_medicaid_share\",\n",
    "        \"HINS5_tricare_share\", \"HINS6_va_share\",\n",
    "        \"POVPIP_lt138_share\",\n",
    "        \"PINCP_mean\", \"WAGP_mean\", \"SEMP_mean_if_positive\",\n",
    "        \"SSP_per_capita\", \"RETP_positive_share\",\n",
    "        \"ESR_unemp_or_nilf_share\", \"ESR_in_labor_force_share\",\n",
    "        \"SCHL_bach_plus_share\",\n",
    "        \"DOUT_diff_share\", \"DPHY_diff_share\", \"DIS_any_share\",\n",
    "        \"FER_births_per_1000_women_15_50\",\n",
    "        \"BROADBND_yes_share\", \"VEH_mean_per_person\",\n",
    "        \"MIL_veteran_share\", \"MIL_active_duty_share\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"State-year rows\", features.count())\n",
    "features.orderBy(\"YEAR\", \"ST\").show(10, truncate=False)\n",
    "\n",
    "\n",
    "out_panel = \"/s/chopin/b/grad/C837217249/project/final_state_panel\"\n",
    "features.write.mode(\"overwrite\").option(\"header\", True).csv(out_panel)\n",
    "print(\"State-level panel saved to:\", out_panel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d4c2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- STATE_NAME: string (nullable = true)\n",
      " |-- TOTAL_HEALTH_SPENDING: double (nullable = true)\n",
      " |-- AGEP_65plus_share: double (nullable = true)\n",
      " |-- AGEP_0_17_share: double (nullable = true)\n",
      " |-- SEX_female_share: double (nullable = true)\n",
      " |-- MAR_ever_married_share: double (nullable = true)\n",
      " |-- HICOV_uninsured_share: double (nullable = true)\n",
      " |-- HINS1_employer_share: double (nullable = true)\n",
      " |-- HINS2_direct_share: double (nullable = true)\n",
      " |-- HINS3_medicare_share: double (nullable = true)\n",
      " |-- HINS4_medicaid_share: double (nullable = true)\n",
      " |-- HINS5_tricare_share: double (nullable = true)\n",
      " |-- HINS6_va_share: double (nullable = true)\n",
      " |-- POVPIP_lt138_share: double (nullable = true)\n",
      " |-- PINCP_mean: double (nullable = true)\n",
      " |-- WAGP_mean: double (nullable = true)\n",
      " |-- SEMP_mean_if_positive: double (nullable = true)\n",
      " |-- SSP_per_capita: double (nullable = true)\n",
      " |-- RETP_positive_share: double (nullable = true)\n",
      " |-- ESR_unemp_or_nilf_share: double (nullable = true)\n",
      " |-- ESR_in_labor_force_share: double (nullable = true)\n",
      " |-- SCHL_bach_plus_share: double (nullable = true)\n",
      " |-- DOUT_diff_share: double (nullable = true)\n",
      " |-- DPHY_diff_share: double (nullable = true)\n",
      " |-- DIS_any_share: double (nullable = true)\n",
      " |-- FER_births_per_1000_women_15_50: double (nullable = true)\n",
      " |-- BROADBND_yes_share: double (nullable = true)\n",
      " |-- VEH_mean_per_person: double (nullable = true)\n",
      " |-- MIL_veteran_share: double (nullable = true)\n",
      " |-- MIL_active_duty_share: double (nullable = true)\n",
      "\n",
      "+----+---+----------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+-------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "|YEAR| ST|STATE_NAME|TOTAL_HEALTH_SPENDING|  AGEP_65plus_share|    AGEP_0_17_share|  SEX_female_share|MAR_ever_married_share|HICOV_uninsured_share|HINS1_employer_share| HINS2_direct_share|HINS3_medicare_share|HINS4_medicaid_share| HINS5_tricare_share|      HINS6_va_share| POVPIP_lt138_share|        PINCP_mean|         WAGP_mean|SEMP_mean_if_positive|    SSP_per_capita|RETP_positive_share|ESR_unemp_or_nilf_share|ESR_in_labor_force_share|SCHL_bach_plus_share|    DOUT_diff_share|     DPHY_diff_share|      DIS_any_share|FER_births_per_1000_women_15_50|BROADBND_yes_share|VEH_mean_per_person|   MIL_veteran_share|MIL_active_duty_share|\n",
      "+----+---+----------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+-------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "|2019|  1|   Alabama|               6267.0|0.17420717350048998| 0.2215276396872645|0.5159356622277153|    0.5479921724348561|  0.10098170882803728|  0.5333119186814285|0.13236192393311694|  0.2088142707240294| 0.19599933512604562| 0.05172433836373704|0.027720553069076528|0.22397115344413887|28160.502641446325| 19891.79276531479|   32417.354083587965| 2763.078986413933|0.12211756235997621|     0.3607357258598238|      0.4651158379706252| 0.18742715194307374|0.06124631234595472|  0.0919398309466194|0.16562438496609858|              51.43216049588196|0.7700413098832698| 2.2044993203397385| 0.07959499794521316| 0.003445107618823275|\n",
      "|2019|  2|    Alaska|              10777.0|0.12736332009650808|0.24383189004094075| 0.482634697797128|    0.5112453779330048|  0.11482137120751287|  0.5510583764498425|0.07580121523624657| 0.13653568816682501| 0.21025910914571216| 0.12886425305346902|0.044991080521362324|0.15571427595021495|36067.735409304965|25936.937823373817|   29700.139058059278| 1705.404561578577|0.10492724302674476|     0.2966639099440226|      0.5092277303515164| 0.20978613755818165|0.03408129370031919| 0.05322707420596136|0.11599423138699602|               63.6943061058805|0.8122220779309544| 2.0237374324204254| 0.09465993206159566|  0.02441134858416092|\n",
      "|2019|  4|   Arizona|               6444.0| 0.1794148611630319|  0.225106842318502|0.5022475801710659|      0.52492369190889|  0.11713328049435086|  0.5000379874639995|0.12432877937141944| 0.19611684311946734| 0.21027799267370884| 0.03579861670676302| 0.02944131500098163|0.19214883612043165| 31789.02199041397|22242.152430160426|    34913.60057111129| 2738.600812478353|0.12058828499583099|    0.34301828193073036|      0.4805383970828925| 0.21443998990481428|0.04619935079217945| 0.06615341687278128|0.13329230961995087|             53.440942765649986|0.7964131590773483|  2.146603858894363| 0.07499563453284418| 0.003178719546315649|\n",
      "|2019|  5|  Arkansas|               6606.0|0.17306558013707982|0.23148620652633503|0.5115709966584974|    0.5584855742785151|  0.09603937167556276| 0.46428992737765606| 0.1285421452155276|  0.2086745858909326| 0.26479817774779274|0.032998166878962315| 0.03248454836695822|0.24122905264887978|26926.346112272367| 19013.43031555396|   30170.524638457417| 2687.262244333959|0.10813989245159726|     0.3536846660684392|      0.4647011535540413| 0.16507831522524324|0.06683899948439329| 0.10063874260886393|0.18015318423595436|               54.0839042573386|0.7540241181998566|  2.073541224015874| 0.07467781207792157| 0.002271519290185...|\n",
      "|2019|  6|California|               8218.0| 0.1476852112319775| 0.2247371402008943|0.5027187662916359|   0.49412681741546155|  0.07953652721589469|  0.5250220166048364|0.11989581046857323| 0.15724268411827905| 0.25615463346620615| 0.02081631802898055|0.014900933313724211|  0.173582513947646| 39076.37701467721| 29269.93172264694|    42880.90672105757|1896.7513796933167|0.08813951065218477|     0.3134100047977559|      0.5131628002808144|   0.249605444877146| 0.0451796903454407|0.056417099083491205| 0.1091148174578788|             46.749769648568844|0.8441916315363982| 2.2916836392627165|0.043255829974436014| 0.003589901788112504|\n",
      "+----+---+----------+---------------------+-------------------+-------------------+------------------+----------------------+---------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+------------------+------------------+---------------------+------------------+-------------------+-----------------------+------------------------+--------------------+-------------------+--------------------+-------------------+-------------------------------+------------------+-------------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\"/s/chopin/b/grad/C837217249/project/final_state_panel\", header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1956c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"/s/chopin/b/grad/C837217249/project/final_panel_single\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
